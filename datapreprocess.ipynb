{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "import ast\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = './tinyquickdraw_data/csv_trans/'\n",
    "JSON_PATH = './tinyquickdraw_data/quickdraw_simplified'\n",
    "DRAW_PATH = './tinyquickdraw_data/sketches/sketches/'\n",
    "IMAGE_PATH = './tinyquickdraw_data/images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ndjson to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FLIE = os.listdir(JSON_PATH)\n",
    "\n",
    "for cls in DATA_FLIE[:1]:\n",
    "    print(cls)\n",
    "    path = os.path.join(JSON_PATH, cls)\n",
    "    csv_file_name = cls.split('.')[0] + '.csv'\n",
    "    csv_save = CSV_PATH + csv_file_name\n",
    "    print(f'{csv_file_name} processing...')\n",
    "\n",
    "    with open(path, 'r', encoding='utf-8', newline=\"\") as lines, open(csv_save, 'w', encoding='utf-8',newline=\"\") as output_w:\n",
    "        writer = csv.writer(output_w)\n",
    "        writer.writerow(['key_id', 'drawing'])\n",
    "        for line in lines:\n",
    "            data = json.loads(line)\n",
    "            if data['recognized'] == True:\n",
    "                writer.writerow([data['key_id'], data['drawing']])\n",
    "\n",
    "    print(f'{csv_file_name} Done...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class 100개, 5000개씩 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['golf club.csv', 'tent.csv', 'rhinoceros.csv', 'river.csv', 'pliers.csv', 'octagon.csv', 'mug.csv', 'cactus.csv', 'saw.csv', 'pig.csv', 'basket.csv', 'ear.csv', 'stove.csv', 'dragon.csv', 'pineapple.csv', 'peanut.csv', 'drill.csv', 'eraser.csv', 'house plant.csv', 'saxophone.csv', 'donut.csv', 'broccoli.csv', 'snowflake.csv', 'hamburger.csv', 'sea turtle.csv', 'line.csv', 'crown.csv', 'shovel.csv', 'ice cream.csv', 'mouse.csv', 'power outlet.csv', 'helmet.csv', 'camera.csv', 'knife.csv', 'door.csv', 'light bulb.csv', 'mushroom.csv', 'duck.csv', 'table.csv', 'broom.csv', 'van.csv', 'microwave.csv', 'see saw.csv', 'carrot.csv', 'church.csv', 'bicycle.csv', 'mermaid.csv', 'cloud.csv', 'sleeping bag.csv', 'ambulance.csv', 'fan.csv', 'rabbit.csv', 'pear.csv', 'couch.csv', 'paint can.csv', 'shark.csv', 'swing set.csv', 'blueberry.csv', 'swan.csv', 'potato.csv', 'piano.csv', 'The Great Wall of China.csv', 'kangaroo.csv', 'floor lamp.csv', 'barn.csv', 'cow.csv', 'truck.csv', 'traffic light.csv', 'roller coaster.csv', 'chandelier.csv', 'angel.csv', 'grapes.csv', 'flip flops.csv', 'speedboat.csv', 'star.csv', 'pillow.csv', 'hedgehog.csv', 'grass.csv', 'zebra.csv', 'asparagus.csv', 'snowman.csv', 'shoe.csv', 'string bean.csv', 'windmill.csv', 'jacket.csv', 'onion.csv', 'submarine.csv', 'fire hydrant.csv', 'diving board.csv', 'headphones.csv', 'fence.csv', 'bracelet.csv', 'pond.csv', 'elbow.csv', 'beach.csv', 'cup.csv', 'giraffe.csv', 'sink.csv', 'sweater.csv', 'tree.csv']\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "csv_save_dir = './tinyquickdraw_data/csvs'\n",
    "\n",
    "csvs = os.listdir(CSV_PATH)\n",
    "classes = [csv_file for csv_file in os.listdir(CSV_PATH)]\n",
    "choice_cls = random.sample(classes, 100)\n",
    "print(choice_cls)\n",
    "for csv_f in choice_cls:\n",
    "    shutil.copy2(os.path.join(CSV_PATH,csv_f), os.path.join(csv_save_dir, csv_f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### key 별 csv 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:09<00:00, 520.68it/s]\n",
      "100%|██████████| 5000/5000 [00:09<00:00, 505.13it/s]\n",
      "100%|██████████| 5000/5000 [00:09<00:00, 503.28it/s]\n",
      "100%|██████████| 5000/5000 [00:10<00:00, 497.50it/s]\n",
      "100%|██████████| 5000/5000 [00:10<00:00, 482.23it/s]\n",
      "100%|██████████| 5000/5000 [00:10<00:00, 480.06it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 289.28it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 283.43it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 281.65it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 273.70it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 273.44it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 278.87it/s]\n",
      "100%|██████████| 5000/5000 [00:19<00:00, 261.42it/s]\n",
      "100%|██████████| 5000/5000 [00:19<00:00, 259.04it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 287.28it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 290.68it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 273.95it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 276.21it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 277.91it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 267.02it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 270.34it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 267.12it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 277.27it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 272.52it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 272.85it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 282.54it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 283.50it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 284.37it/s]\n",
      "100%|██████████| 5000/5000 [00:19<00:00, 251.73it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 265.63it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 292.22it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 289.88it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 296.50it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 303.10it/s]\n",
      "100%|██████████| 5000/5000 [00:15<00:00, 324.89it/s]\n",
      "100%|██████████| 5000/5000 [00:14<00:00, 335.81it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 304.79it/s]\n",
      "100%|██████████| 5000/5000 [00:15<00:00, 321.99it/s]\n",
      "100%|██████████| 5000/5000 [00:15<00:00, 325.62it/s]\n",
      "100%|██████████| 5000/5000 [00:15<00:00, 320.11it/s]\n",
      "100%|██████████| 5000/5000 [00:15<00:00, 315.37it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 300.62it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 294.28it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 289.66it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 277.43it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 272.80it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 284.13it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 286.67it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 281.37it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 295.11it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 291.25it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 291.20it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 284.76it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 292.49it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 291.65it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 297.89it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 286.16it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 291.30it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 295.30it/s]\n",
      "100%|██████████| 5000/5000 [00:23<00:00, 215.80it/s]\n",
      "100%|██████████| 5000/5000 [00:20<00:00, 240.13it/s]\n",
      "100%|██████████| 5000/5000 [00:19<00:00, 259.29it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 263.73it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 265.40it/s]\n",
      "100%|██████████| 5000/5000 [00:20<00:00, 249.33it/s]\n",
      "100%|██████████| 5000/5000 [00:20<00:00, 242.29it/s]\n",
      "100%|██████████| 5000/5000 [00:19<00:00, 259.20it/s]\n",
      "100%|██████████| 5000/5000 [00:20<00:00, 248.66it/s]\n",
      "100%|██████████| 5000/5000 [00:19<00:00, 262.03it/s]\n",
      "100%|██████████| 5000/5000 [00:19<00:00, 261.84it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 263.23it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 264.23it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 268.55it/s]\n",
      "100%|██████████| 5000/5000 [00:19<00:00, 262.21it/s]\n",
      "100%|██████████| 5000/5000 [00:20<00:00, 248.32it/s]\n",
      "100%|██████████| 5000/5000 [00:20<00:00, 248.66it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 274.62it/s]\n",
      "100%|██████████| 5000/5000 [00:21<00:00, 232.99it/s]\n",
      "100%|██████████| 5000/5000 [00:21<00:00, 235.08it/s]\n",
      "100%|██████████| 5000/5000 [00:19<00:00, 256.58it/s]\n",
      "100%|██████████| 5000/5000 [00:20<00:00, 238.28it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 292.09it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 266.12it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 289.06it/s]\n",
      "100%|██████████| 5000/5000 [00:19<00:00, 251.44it/s]\n",
      "100%|██████████| 5000/5000 [00:19<00:00, 261.12it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 267.14it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 296.00it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 274.32it/s]\n",
      "100%|██████████| 5000/5000 [00:15<00:00, 319.78it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 272.26it/s]\n",
      "100%|██████████| 5000/5000 [00:16<00:00, 298.25it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 267.46it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 275.51it/s]\n",
      "100%|██████████| 5000/5000 [00:15<00:00, 313.64it/s]\n",
      "100%|██████████| 5000/5000 [00:19<00:00, 251.60it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 285.19it/s]\n",
      "100%|██████████| 5000/5000 [00:18<00:00, 272.53it/s]\n",
      "100%|██████████| 5000/5000 [00:20<00:00, 239.22it/s]\n",
      "100%|██████████| 5000/5000 [00:17<00:00, 277.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['golf club', 'tent', 'rhinoceros', 'river', 'pliers', 'octagon', 'mug', 'cactus', 'saw', 'pig', 'basket', 'ear', 'stove', 'dragon', 'pineapple', 'peanut', 'drill', 'eraser', 'house plant', 'saxophone', 'donut', 'broccoli', 'snowflake', 'hamburger', 'sea turtle', 'line', 'crown', 'shovel', 'ice cream', 'mouse', 'power outlet', 'helmet', 'camera', 'knife', 'door', 'light bulb', 'mushroom', 'duck', 'table', 'broom', 'van', 'microwave', 'see saw', 'carrot', 'church', 'bicycle', 'mermaid', 'cloud', 'sleeping bag', 'ambulance', 'fan', 'rabbit', 'pear', 'couch', 'paint can', 'shark', 'swing set', 'blueberry', 'swan', 'potato', 'piano', 'The Great Wall of China', 'kangaroo', 'floor lamp', 'barn', 'cow', 'truck', 'traffic light', 'roller coaster', 'chandelier', 'angel', 'grapes', 'flip flops', 'speedboat', 'star', 'pillow', 'hedgehog', 'grass', 'zebra', 'asparagus', 'snowman', 'shoe', 'string bean', 'windmill', 'jacket', 'onion', 'submarine', 'fire hydrant', 'diving board', 'headphones', 'fence', 'bracelet', 'pond', 'elbow', 'beach', 'cup', 'giraffe', 'sink', 'sweater', 'tree']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "save_key_data = './tinyquickdraw_data/key_data'\n",
    "names = []\n",
    "for csv_file in choice_cls:\n",
    "    path = os.path.join(CSV_PATH, csv_file)\n",
    "    csv_name = csv_file.split('.')[0]\n",
    "    names.append(csv_name)\n",
    "\n",
    "    rd_csv = pd.read_csv(path)\n",
    "    pick_feature = rd_csv.sample(n=5000, replace=False)\n",
    "    \n",
    "    for i, data in tqdm(pick_feature.iterrows(), total=len(pick_feature)):\n",
    "        pd.DataFrame([data['drawing']], columns=['drawing']).to_csv(f'{save_key_data}/{csv_name}_{data[\"key_id\"]}.csv', index=False)\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 좌표 -> 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in os.listdir(CSV_PATH)[309:310]:\n",
    "    datas = os.path.join(CSV_PATH, cls)\n",
    "    print(datas)\n",
    "    data = pd.read_csv(datas)\n",
    "    for coords in data.iloc[:, 1][2:3]:\n",
    "        new_coord = []\n",
    "        new = ast.literal_eval(coords)\n",
    "        print(new)\n",
    "\n",
    "        for coord in new:\n",
    "            coord = np.array(coord)\n",
    "            new_coord = coord.swapaxes(0, 1)\n",
    "            print(new_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrs = [[[184, 115, 67, 57, 36, 18], [251, 103, 12, 109, 193, 247]], [[145, 154, 150, 48, 24], [180, 176, 175, 178, 173]], [[55, 50, 38, 0, 28, 31, 60, 66, 71], [128, 152, 179, 253, 254, 247, 114, 26, 0]], [[72, 76, 81, 83, 86, 99, 93, 86], [26, 35, 71, 250, 255, 254, 189, 5]], [[67, 74, 97, 172], [12, 16, 49, 194]]]\n",
    "\n",
    "def make_img(arrs): \n",
    "\timage = Image.new(\"P\", (256,256), color=255)\n",
    "\timage_d = ImageDraw.Draw(image)\n",
    "\tfor stroke in arrs:\n",
    "\t\tfor i in range(len(stroke[0]) - 1):\n",
    "\t\t\timage_d.line([stroke[0][i], \n",
    "\t\t\t\t\t\tstroke[1][i], \n",
    "\t\t\t\t\t\tstroke[0][i+1], \n",
    "\t\t\t\t\t\tstroke[1][i+1]], \n",
    "\t\t\t\t\t\tfill=0, width=5)\n",
    "\treturn image\n",
    "\n",
    "img = make_img(arrs) \n",
    "img = img.resize((64,64))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### npz 이미지 열기 -> x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(DRAW_PATH)[309:310]:\n",
    "    path = os.path.join(DRAW_PATH, file)\n",
    "    print(path)\n",
    "    data = np.load(path, encoding='latin1', allow_pickle=True)\n",
    "    print(data.files)\n",
    "    \n",
    "    print(data['test'].shape)\n",
    "    print(data['train'].shape)\n",
    "    print(data['valid'].shape)\n",
    "    print(data['train'][0].shape)\n",
    "    print(data['train'][1].shape)\n",
    "\n",
    "    image = Image.fromarray(data['train'][0])   \n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### npy 이미지 열기 -> x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_file in os.listdir(IMAGE_PATH)[:1]:\n",
    "    path = os.path.join(IMAGE_PATH, image_file)\n",
    "    images = np.load(path, encoding=\"latin1\", allow_pickle=True)\n",
    "    print(images.shape)\n",
    "    for image in images[:1]:\n",
    "        img_arr = image.reshape(28, 28)\n",
    "        img = Image.fromarray(img_arr)\n",
    "        img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 좌표로 이미지 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_SIZE = 256\n",
    "\n",
    "def draw_cv2(raw_strokes, size=256, lw=6, time_color=True):\n",
    "    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n",
    "    for t, stroke in enumerate(raw_strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            color = 255 - min(t, 10) * 13 if time_color else 255\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]),\n",
    "                        (stroke[0][i + 1], stroke[1][i + 1]), color, lw)\n",
    "    if size != BASE_SIZE:\n",
    "        return cv2.resize(img, (size, size))\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "### 획마다 가중치\n",
    "def draw_cv2_v2(raw_strokes, size=256, lw=6, augmentation = False):\n",
    "    img = np.zeros((BASE_SIZE, BASE_SIZE, 3), np.uint8)\n",
    "    for t, stroke in enumerate(raw_strokes):\n",
    "        points_count = len(stroke[0]) - 1\n",
    "        grad = 255//points_count\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), (255, 255 - min(t,10)*13, max(255 - grad*i, 20)), lw)\n",
    "    if size != BASE_SIZE:\n",
    "        img = cv2.resize(img, (size, size))\n",
    "    if augmentation:\n",
    "        if random.random() > 0.5:\n",
    "            img = np.fliplr(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "arrs = [[[184, 115, 67, 57, 36, 18], [251, 103, 12, 109, 193, 247]], [[145, 154, 150, 48, 24], [180, 176, 175, 178, 173]], [[55, 50, 38, 0, 28, 31, 60, 66, 71], [128, 152, 179, 253, 254, 247, 114, 26, 0]], [[72, 76, 81, 83, 86, 99, 93, 86], [26, 35, 71, 250, 255, 254, 189, 5]], [[67, 74, 97, 172], [12, 16, 49, 194]]]\n",
    "\n",
    "# for arr in arrs:\n",
    "x = draw_cv2(arrs[:1], size=224)\n",
    "cv2.imshow('tt', x)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "import ast\n",
    "\n",
    "arrs = str(arrs)\n",
    "stroke_vec = ast.literal_eval(arrs)\n",
    "print(stroke_vec)\n",
    "in_strokes = [(xi,yi,i) for i,(x,y) in enumerate(stroke_vec) for xi,yi in zip(x,y)]\n",
    "print(in_strokes)\n",
    "c_strokes = np.stack(in_strokes)\n",
    "print(c_strokes[:5])\n",
    "c_strokes[:,2] = [1]+np.diff(c_strokes[:,2]).tolist()\n",
    "print(\"???\", c_strokes)\n",
    "c_strokes[:,2] += 1\n",
    "print(\"+1\", c_strokes)\n",
    "c_strokes= c_strokes.swapaxes(0, 1)\n",
    "print(\"swap\", c_strokes)\n",
    "seq = pad_sequences(c_strokes, maxlen=70, padding='post')\n",
    "print(\"padding\", seq)\n",
    "seq = seq.swapaxes(0, 1)\n",
    "print(\"swapping\", seq)\n",
    "print(seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "def pad_sequences(strokes, seq_lengths):\n",
    "    seq_tensor = np.zeros((seq_lengths, 3))\n",
    "    for idx, stroke in enumerate(strokes):\n",
    "        seq_tensor[idx, :] = stroke\n",
    "    # for idx, (seq, seqlen) in enumerate(zip(strokes, seq_lengths)):\n",
    "    #     seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
    "    return seq_tensor\n",
    "\n",
    "arrs = [[[184, 115, 67, 57, 36, 18], [251, 103, 12, 109, 193, 247]], [[145, 154, 150, 48, 24], [180, 176, 175, 178, 173]], [[55, 50, 38, 0, 28, 31, 60, 66, 71], [128, 152, 179, 253, 254, 247, 114, 26, 0]], [[72, 76, 81, 83, 86, 99, 93, 86], [26, 35, 71, 250, 255, 254, 189, 5]], [[67, 74, 97, 172], [12, 16, 49, 194]]]\n",
    "\n",
    "arrs = str(arrs)\n",
    "stroke_vec = ast.literal_eval(arrs)\n",
    "print(stroke_vec)\n",
    "in_strokes = [(xi,yi,i) for i,(x,y) in enumerate(stroke_vec) for xi,yi in zip(x,y)]\n",
    "print(in_strokes)\n",
    "c_strokes = np.stack(in_strokes)\n",
    "print(c_strokes[:5])\n",
    "c_strokes[:,2] = [1]+np.diff(c_strokes[:,2]).tolist()\n",
    "print(\"???\", c_strokes)\n",
    "c_strokes[:,2] += 1\n",
    "print(\"+1\", c_strokes)\n",
    "# c_strokes= c_strokes.swapaxes(0, 1)\n",
    "# print(\"swap\", c_strokes)\n",
    "\n",
    "print(pad_sequences(c_strokes, 70))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('quickdraw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "298e8e14558290d175deeb4aed5e1a1c833484f9420eec248753b4773b7b5035"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
